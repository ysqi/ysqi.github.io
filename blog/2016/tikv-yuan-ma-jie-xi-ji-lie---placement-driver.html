<!DOCTYPE html><html lang="zh"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><title>TiKV源码解析系列-PlacementDriver - 虞双齐爱折腾</title><link rel="alternate" hreflang="zh" href="https://yushuangqi.com"><meta name="renderer" content="webkit"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="MobileOptimized" content="width"><meta name="HandheldFriendly" content="true"><meta name="applicable-device" content="pc,mobile"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="theme-color" content="#f8f5ec"><meta name="msapplication-navbutton-color" content="#f8f5ec"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec"><meta name="mobile-web-app-capable" content="yes"><meta name="author" content="虞双齐"><meta name="description" content="本系列文章主要面向 TiKV 社区开发者，重点介绍 TiKV 的系统架构，源码结构，流程解析。目的是使得开发者阅读之后，能对 TiKV 项目有一个初步了解，更好的参与进入"><meta name="keywords" content="智能合约开发, Go语言, 区块链技术"><meta name="generator" content="Hugo 0.37.1"><link rel="canonical" href="https://yushuangqi.com/blog/2016/tikv-yuan-ma-jie-xi-ji-lie---placement-driver.html"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="icon" href="/favicon.ico"><link rel="manifest" href="/manifest.json"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link href="/dist/jane.min.css?v=2.7.0" rel="stylesheet"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous"><meta property="og:title" content="TiKV源码解析系列-PlacementDriver"><meta property="og:description" content="本系列文章主要面向 TiKV 社区开发者，重点介绍 TiKV 的系统架构，源码结构，流程解析。目的是使得开发者阅读之后，能对 TiKV 项目有一个初步了解，更好的参与进入"><meta property="og:type" content="article"><meta property="og:url" content="https://yushuangqi.com/blog/2016/tikv-yuan-ma-jie-xi-ji-lie---placement-driver.html"><meta property="article:published_time" content="2016-12-31T11:32:32&#43;08:00"><meta property="article:modified_time" content="2016-12-31T11:32:32&#43;08:00"><meta itemprop="name" content="TiKV源码解析系列-PlacementDriver"><meta itemprop="description" content="本系列文章主要面向 TiKV 社区开发者，重点介绍 TiKV 的系统架构，源码结构，流程解析。目的是使得开发者阅读之后，能对 TiKV 项目有一个初步了解，更好的参与进入"><meta itemprop="datePublished" content="2016-12-31T11:32:32&#43;08:00"><meta itemprop="dateModified" content="2016-12-31T11:32:32&#43;08:00"><meta itemprop="wordCount" content="3982"><meta itemprop="keywords" content="github,nosql,mysql,rust,golang,"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="TiKV源码解析系列-PlacementDriver"><meta name="twitter:description" content="本系列文章主要面向 TiKV 社区开发者，重点介绍 TiKV 的系统架构，源码结构，流程解析。目的是使得开发者阅读之后，能对 TiKV 项目有一个初步了解，更好的参与进入"><!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]--><!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]--></head><body><div id="mobile-navbar" class="mobile-navbar"><div class="mobile-header-logo"><a href="/" class="logo">虞双齐爱折腾</a></div><div class="mobile-navbar-icon"><span></span> <span></span> <span></span></div></div><nav id="mobile-menu" class="mobile-menu slideout-menu"><ul class="mobile-menu-list"><a href="/"><li class="mobile-menu-item">首页</li></a><a href="/series.html"><li class="mobile-menu-item">专题</li></a><a href="/categories.html"><li class="mobile-menu-item">分类</li></a><a href="/tags.html"><li class="mobile-menu-item">标签</li></a><a href="/post.html"><li class="mobile-menu-item">归档</li></a><a href="/about.html"><li class="mobile-menu-item">关于</li></a></ul></nav><header id="header" class="header container"><div class="logo-wrapper"><a href="/" class="logo">虞双齐爱折腾</a></div><nav class="site-navbar"><ul id="menu" class="menu"><li class="menu-item"><a class="menu-item-link" href="/">首页</a></li><li class="menu-item"><a class="menu-item-link" href="/series.html">专题</a></li><li class="menu-item"><a class="menu-item-link" href="/categories.html">分类</a></li><li class="menu-item"><a class="menu-item-link" href="/tags.html">标签</a></li><li class="menu-item"><a class="menu-item-link" href="/post.html">归档</a></li><li class="menu-item"><a class="menu-item-link" href="/about.html">关于</a></li></ul></nav></header><div id="mobile-panel"><main id="main" class="main bg-llight"><div class="content-wrapper"><div id="content" class="content container"><article class="post bg-white"><header class="post-header"><h1 class="post-title">TiKV源码解析系列-PlacementDriver</h1><div class="post-meta"><span class="post-time">2016-12-31</span><div class="post-category"><a href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E4%B8%8E%E5%BC%80%E5%8F%91.html">编程语言与开发</a></div><span class="more-meta">约 3982 字 </span><span class="more-meta">预计阅读 8 分钟</span></div></header><div class="post-toc" id="post-toc"><h2 class="post-toc-title">文章目录</h2><div class="post-toc-content always-active"><nav id="TableOfContents"><ul><li><ul><li><a href="#介绍">介绍</a></li><li><a href="#初始化">初始化</a></li><li><a href="#选举">选举</a><ul><li><a href="#tso">TSO</a></li></ul></li><li><a href="#心跳">心跳</a></li><li><a href="#split-merge">Split / Merge</a></li><li><a href="#路由">路由</a></li><li><a href="#小结">小结</a></li></ul></li></ul></nav></div></div><div class="post-content"><p>本系列文章主要面向 TiKV 社区开发者，重点介绍 TiKV 的系统架构，源码结构，流程解析。目的是使得开发者阅读之后，能对 TiKV 项目有一个初步了解，更好的参与进入 TiKV 的开发中。</p><p>TiKV 是一个分布式的 KV 系统，它采用 Raft 协议保证数据的强一致性，同时使用 MVCC + 2PC 的方式实现了分布式事务的支持。</p><p>本文为本系列文章第三节。</p><h2 id="介绍">介绍</h2><p>Placement Driver (后续以 PD 简称) 是 TiDB 里面全局中心总控节点，它负责整个集群的调度，负责全局 ID 的生成，以及全局时间戳 TSO 的生成等。PD 还保存着整个集群 TiKV 的元信息，负责给 client 提供路由功能。</p><p>作为中心总控节点，PD 通过集成 <a href="https://github.com/coreos/etcd">etcd</a> ，自动的支持 auto failover，无需担心单点故障问题。同时，PD 也通过 etcd 的 raft，保证了数据的强一致性，不用担心数据丢失的问题。</p><p>在架构上面，PD 所有的数据都是通过 TiKV 主动上报获知的。同时，PD 对整个 TiKV 集群的调度等操作，也只会在 TiKV 发送 heartbeat 命令的结果里面返回相关的命令，让 TiKV 自行去处理，而不是主动去给 TiKV 发命令。这样设计上面就非常简单，我们完全可以认为 PD 是一个无状态的服务（当然，PD 仍然会将一些信息持久化到 etcd），所有的操作都是被动触发，即使 PD 挂掉，新选出的 PD leader 也能立刻对外服务，无需考虑任何之前的中间状态。</p><h2 id="初始化">初始化</h2><p>PD 集成了 etcd，所以通常，我们需要启动至少三个副本，才能保证数据的安全。现阶段 PD 有集群启动方式，<code>initial-cluster</code> 的静态方式以及 <code>join</code> 的动态方式。</p><p>在继续之前，我们需要了解下 etcd 的端口，在 etcd 里面，默认要监听 2379 和 2380 两个端口。2379 主要是 etcd 用来处理外部请求用的，而 2380 则是 etcd peer 之间相互通信用的。</p><p>假设现在我们有三个 pd，分别为 pd1，pd2，pd3，分别在 host1，host2，host3 上面。</p><p>对于静态初始化，我们直接在三个 PD 启动的时候，给 <code>initial-cluster</code> 设置 <code>pd1=http://host1:2380,pd2=http://host2:2380,pd3=http://host3:2380</code>。</p><p>对于动态初始化，我们先启动 pd1，然后启动 pd2，加入到 pd1 的集群里面，<code>join</code> 设置为 <code>http://host1:2379</code>。然后启动 pd3，加入到 pd1，pd2 形成的集群里面， <code>join</code> 设置为 <code>http://host1:2379</code>。</p><p>可以看到，静态初始化和动态初始化完全走的是两个端口，而且这两个是互斥的，也就是我们只能使用一种方式来初始化集群。etcd 本身只支持 <code>initial-cluster</code> 的方式，但为了方便，PD 同时也提供了 <code>join</code> 的方式。</p><p><code>join</code> 主要是用了 etcd 自身提供的 member 相关 API，包括 add member，list member 等，所以我们使用 2379 端口，因为需要将命令发到 etcd 去执行。而 <code>initial-cluster</code> 则是 etcd 自身的初始化方式，所以使用的 2380 端口。</p><p>相比于 <code>initial-cluster</code>，<code>join</code> 需要考虑非常多的 case（在 <code>server/join.go</code> <code>prepareJoinCluster</code> 函数里面有详细的解释），但 <code>join</code> 的使用非常自然，后续我们会考虑去掉 <code>initial-cluster</code> 的初始化方案。</p><h2 id="选举">选举</h2><p>当 PD 启动之后，我们就需要选出一个 leader 对外提供服务。虽然 etcd 自身也有 raft leader，但我们还是觉得使用自己的 leader，也就是 PD 的 leader 跟 etcd 自己的 leader 是不一样的。</p><p>当 PD 启动之后，Leader 的选举如下：</p><ol><li><p>检查当前集群是不是有 leader，如果有 leader，就 watch 这个 leader，只要发现 leader 掉了，就重新开始 1。</p></li><li><p>如果没有 leader，开始 campaign，创建一个 Lessor，并且通过 etcd 的事务机制写入相关信息，如下：</p><pre><code>// Create a lessor. 
ctx, cancel := context.WithTimeout(s.client.Ctx(), requestTimeout)
leaseResp, err := lessor.Grant(ctx, s.cfg.LeaderLease)
cancel()

// The leader key must not exist, so the CreateRevision is 0.
resp, err := s.txn().
    If(clientv3.Compare(clientv3.CreateRevision(leaderKey), &quot;=&quot;, 0)).
    Then(clientv3.OpPut(leaderKey, s.leaderValue, clientv3.WithLease(clientv3.LeaseID(leaseResp.ID)))).
    Commit()
</code></pre><p>如果 leader key 的 CreateRevision 为 0，表明其他 PD 还没有写入，那么我就可以将我自己的 leader 相关信息写入，同时会带上一个 Lease。如果事务执行失败，表明其他的 PD 已经成为了 leader，那么就重新回到 1。</p></li><li><p>成为 leader 之后，我们对定期进行保活处理:</p><pre><code>// Make the leader keepalived.
ch, err := lessor.KeepAlive(s.client.Ctx(), clientv3.LeaseID(leaseResp.ID))
if err != nil {
    return errors.Trace(err)
}
</code></pre><p>当 PD 崩溃，原先写入的 leader key 会因为 lease 到期而自动删除，这样其他的 PD 就能 watch 到，重新开始选举。</p></li><li><p>初始化 raft cluster，主要是从 etcd 里面重新载入集群的元信息。拿到最新的 TSO 信息：</p><pre><code>// Try to create raft cluster.
err = s.createRaftCluster()
if err != nil {
    return errors.Trace(err)
}

log.Debug(&quot;sync timestamp for tso&quot;)
if err = s.syncTimestamp(); err != nil {
    return errors.Trace(err)
}
</code></pre></li><li><p>所有做完之后，开始定期更新 TSO，监听 lessor 是否过期，以及外面是否主动退出：</p><pre><code>for {
    select {
    case _, ok := &lt;-ch:
        if !ok {
            log.Info(&quot;keep alive channel is closed&quot;)
            return nil
        }
    case &lt;-tsTicker.C:
        if err = s.updateTimestamp(); err != nil {
            return errors.Trace(err)
        }
    case &lt;-s.client.Ctx().Done():
        return errors.New(&quot;server closed&quot;)
    }
}
</code></pre></li></ol><h3 id="tso">TSO</h3><p>前面我们说到了 TSO，TSO 是一个全局的时间戳，它是 TiDB 实现分布式事务的基石。所以对于 PD 来说，我们首先要保证它能快速大量的为事务分配 TSO，同时也需要保证分配的 TSO 一定是单调递增的，不可能出现回退的情况。</p><p>TSO 是一个 int64 的整形，它由 physical time + logical time 两个部分组成。Physical time 是当前 unix time 的毫秒时间，而 logical time 则是一个最大 <code>1 &lt;&lt; 18</code> 的计数器。也就是说 1ms，PD 最多可以分配 262144 个 TSO，这个能满足绝大多数情况了。</p><p>对于 TSO 的保存于分配，PD 会做如下处理：</p><ol><li><p>当 PD 成为 leader 之后，会从 etcd 上面获取上一次保存的时间，如果发现本地的时间比这个大，则会继续等待直到当前的时间大于这个值：</p><pre><code>last, err := s.loadTimestamp()
if err != nil {
    return errors.Trace(err)
}

var now time.Time

for {
    now = time.Now()
    if wait := last.Sub(now) + updateTimestampGuard; wait &gt; 0 {
        log.Warnf(&quot;wait %v to guarantee valid generated timestamp&quot;, wait)
        time.Sleep(wait)
        continue
    }
    break
}
</code></pre></li><li><p>当 PD 能分配 TSO 之后，首先会向 etcd 申请一个最大的时间，譬如，假设当前时间是 t1，每次最多能申请 3s 的时间窗口，PD 会向 etcd 保存 t1 + 3s 的时间值，然后 PD 就能在内存里面直接使用这一段时间窗口.当当前的时间 t2 大于 t1 + 3s 之后，PD 就会在向 etcd 继续更新为 t2 + 3s：</p><pre><code>if now.Sub(s.lastSavedTime) &gt;= 0 {
    last := s.lastSavedTime
    save := now.Add(s.cfg.TsoSaveInterval.Duration)
    if err := s.saveTimestamp(save); err != nil {
        return errors.Trace(err)
    }
}
</code></pre><p>这么处理的好处在于，即使 PD 当掉，新启动的 PD 也会从上一次保存的最大的时间之后开始分配 TSO，也就是 1 处理的情况。</p></li><li><p>因为 PD 在内存里面保存了一个可分配的时间窗口，所以外面请求 TSO 的时候，PD 能直接在内存里面计算 TSO 并返回。</p><pre><code>resp := pdpb.Timestamp{}
for i := 0; i &lt; maxRetryCount; i++ {
    current, ok := s.ts.Load().(*atomicObject)
    if !ok {
        log.Errorf(&quot;we haven't synced timestamp ok, wait and retry, retry count %d&quot;, i)
        time.Sleep(200 * time.Millisecond)
        continue
    }

    resp.Physical = current.physical.UnixNano() / int64(time.Millisecond)
    resp.Logical = atomic.AddInt64(&amp;current.logical, int64(count))
    if resp.Logical &gt;= maxLogical {
        log.Errorf(&quot;logical part outside of max logical interval %v, please check ntp time, retry count %d&quot;, resp, i)
        time.Sleep(updateTimestampStep)
        continue
    }
    return resp, nil
}
</code></pre><p>因为是在内存里面计算的，所以性能很高，我们自己内部测试每秒能分配百万级别的 TSO。</p></li><li><p>如果 client 每次事务都向 PD 来请求一次 TSO，每次 RPC 的开销也是非常大的，所以 client 会批量的向 PD 获取 TSO。client 会首先收集一批事务的 TSO 请求，譬如 n 个，然后直接向 PD 发送命令，参数就是 n，PD 收到命令之后，会生成 n 个 TSO 返回给客户端。</p></li></ol><h2 id="心跳">心跳</h2><p>在最开始我们说过，PD 所有关于集群的数据都是由 TiKV 主动心跳上报的，PD 对 TiKV 的调度也是在心跳的时候完成的。通常 PD 会处理两种心跳，一个是 TiKV 自身 store 的心跳，而另一个则是 store 里面 region 的 leader peer 上报的心跳。</p><p>对于 store 的心跳，PD 在 <code>handleStoreHeartbeat</code> 函数里面处理，主要就是将心跳里面当前的 store 的一些状态缓存到 cache 里面。store 的状态包括该 store 有多少个 region，有多少个 region 的 leader peer 在该 store 上面等，这些信息都会用于后续的调度。</p><p>对于 region 的心跳，PD 在 <code>handleRegionHeartbeat</code> 里面处理。这里需要注意，只有 leader peer 才会去上报所属 region 的信息，follower peer 是不会上报的。收到 region 的心跳之后，首先 PD 也会将其放入 cache 里面，如果 PD 发现 region 的 epoch 有变化，就会将这个 region 的信息也保存到 etcd 里面。然后，PD 会对这个 region 进行具体的调度，譬如发现 peer 数目不够，添加新的 peer，或者有一个 peer 已经坏了，删除这个 peer 等，详细的调度实现，我们会在后续讨论。</p><p>这里再说一下 region 的 epoch，在 region 的 epoch 里面，有 <code>conf_ver</code> 和 <code>version</code>，分别表示这个 region 不同的版本状态。如果一个 region 发生了 membership changes，也就是新增或者删除了 peer，<code>conf_ver</code> 会加 1，如果 region 发生了 <code>split</code> 或者 <code>merge</code>，则 <code>version</code> 加 1。</p><p>无论是 PD 还是在 TiKV，我们都是通过 epoch 来判断 region 是否发生了变化，从而拒绝掉一些危险的操作。譬如 region 已经发生了分裂，<code>version</code> 变成了 2，那么如果这时候有一个写请求带上的 <code>version</code> 是 1， 我们就会认为这个请求是 stale，会直接拒绝掉。因为 <code>version</code> 变化表明 region 的范围已经发生了变化，很有可能这个 stale 的请求需要操作的 key 是在之前的 region range 里面而没在新的 range 里面。</p><h2 id="split-merge">Split / Merge</h2><p>前面我们说了，PD 会在 region 的 heartbeat 里面对 region 进行调度，然后直接在 heartbeat 的返回值里面带上相关的调度信息，让 TiKV 自己去处理，TiKV 处理完成之后，通过下一个 heartbeat 重新上报，PD 就能知道是否调度成功了。</p><p>对于 membership changes，比较容易，因为我们有最大副本数的配置，假设三个，那么当 region 的心跳上来，发现只有两个 peer，那么就 add peer，如果有四个 peer，就 remove peer。而对于 region 的 split / merge，则情况稍微要复杂一点，但也比较简单。注意，现阶段，我们只支持 split，merge 处于开发阶段，没对外发布，所以这里仅仅以 split 举例：</p><ol><li><p>在 TiKV 里面，leader peer 会定期检查 region 所占用的空间是否超过某一个阀值，假设我们设置 region 的 size 为 64MB，如果一个 region 超过了 96MB， 就需要分裂。</p></li><li><p>Leader peer 会首先向 PD 发送一个请求分裂的命令，PD 在 <code>handleAskSplit</code> 里面处理，因为我们是一个 region 分裂成两个，对于这两个新分裂的 region，一个会继承之前 region 的所有的元信息，而另一个相关的信息，譬如 region ID，新的 peer ID，则需要 PD 生成，并将其返回给 leader。</p></li><li><p>Leader peer 写入一个 split raft log，在 apply 的时候执行，这样 region 就分裂成了两个。</p></li><li><p>分裂成功之后，TiKV 告诉 PD，PD 就在 <code>handleReportSplit</code> 里面处理，更新 cache 相关的信息，并持久化到 etcd。</p></li></ol><h2 id="路由">路由</h2><p>因为 PD 保存了所有 TiKV 的集群信息，自然对 client 提供了路由的功能。假设 client 要对 <code>key</code> 写入一个值。</p><ol><li><p>client 先从 PD 获取 <code>key</code> 属于哪一个 region，PD 将这个 region 相关的元信息返回。</p></li><li><p>client 自己 cache，这样就不需要每次都从 PD 获取。然后直接给 region 的 leader peer 发送命令。</p></li><li><p>有可能 region 的 leader 已经漂移到其他 peer，TiKV 会返回 <code>NotLeader</code> 错误，并带上新的 leader 的地址，client 在 cache 里面更新，并重新向新的 leader 发送请求。</p></li><li><p>也有可能 region 的 version 已经变化，譬如 split 了，这时候，<code>key</code> 可能已经落入了新的 region 上面，client 会收到 <code>StaleCommand</code> 的错误，于是重新从 PD 获取，进入状态 1。</p></li></ol><h2 id="小结">小结</h2><p>PD 作为 TiDB 集群的中心调度模块，在设计上面，我们尽量保证无状态，方便扩展。本篇文章主要介绍了 PD 是如何跟 TiKV，TiDB 协作交互的。后面，我们会详细地介绍核心调度功能，也就是 PD 是如何控制整个集群的。</p></div><div style="height:130px"><div class="post-copyright" style="float:left"><p class="copyright-item"><span class="item-title">文章作者</span> <span class="item-content">虞双齐</span></p><p class="copyright-item"><span class="item-title">上次更新</span> <span class="item-content">2016-12-31</span></p><p class="copyright-item"><span class="item-title">许可协议</span> <span class="item-content"><a target="_blank" rel="license noopener external nofollow" href="https://creativecommons.org/licenses/by/4.0/deed.zh">署名 4.0 国际</a></span></p></div><div class="post-copyright" style="float:right"><a href="https://info.flagcounter.com/8B1z" target="_blank" rel="noopener external nofollow"><img src="https://s05.flagcounter.com/countxl/8B1z/bg_FFFFFF/txt_000000/border_CCCCCC/columns_4/maxflags_12/viewers_0/labels_0/pageviews_1/flags_0/percent_0/" alt="Flag Counter" border="0"></a></div></div><div class="post-reward"><input type="checkbox" name="reward" id="reward" hidden> <label class="reward-button" for="reward">赞赏支持</label><div class="qr-code"><label class="qr-code-image" for="reward"><img class="image" src="/img/donateMe_wechat.png"> <span>微信打赏</span></label></div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/github.html">github</a> <a href="/tags/nosql.html">nosql</a> <a href="/tags/mysql.html">mysql</a> <a href="/tags/rust.html">rust</a> <a href="/tags/golang.html">golang</a></div><nav class="post-nav"><a class="prev" href="/blog/2016/ji-yu-golangde-ipde-zhi-xin-xi-cha-xun-fu-wu.html"><i class="iconfont icon-left"></i> <span class="prev-text nav-default">基于Golang的IP地址信息查询服务</span> <span class="prev-text nav-mobile">上一篇</span> </a><a class="next" href="/blog/2016/golang-dui-zi-ding-yi-lei-xing-pai-xu.html"><span class="next-text nav-default">golang对自定义类型排序</span> <span class="prev-text nav-mobile">下一篇</span> <i class="iconfont icon-right"></i></a></nav></footer><div class="disqus-button" id="load_disqus" onclick="load_disqus()">显示 Disqus 评论</div><div id="disqus_thread"></div><script type="text/javascript">function load_disqus() {
        
        
        if (window.location.hostname === 'localhost') return;

        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        var disqus_shortname = 'yushuangqi';
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);

        $('#load_disqus').remove();
    };</script><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></article></div></div></main><footer id="footer" class="footer"><div class="social-links"><a href="mailto:ysqi@yushuangqi.com" rel="me" class="iconfont icon-email" title="email"></a> <a href="http://github.com/ysqi" rel="me" class="iconfont icon-github" title="github"></a> <a href="https://weibo.com/234665601" rel="me" class="iconfont icon-weibo" title="weibo"></a> <a href="https://www.zhihu.com/people/_ysqi/" rel="me" class="iconfont icon-zhihu" title="zhihu"></a> <a href="https://yushuangqi.com/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a></div><div class="copyright"><span class="power-by">Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a> </span><span class="division">|</span> <span class="theme-info">Theme - <a class="theme-link" href="https://github.com/xianmin/hugo-theme-jane">Jane</a> </span><span class="copyright-year">&copy; 2014 - 2018 <span class="heart"><i class="iconfont icon-heart"></i> </span><span class="author">虞双齐</span></span></div></footer><div class="back-to-top" id="back-to-top"><i class="iconfont icon-up"></i></div></div><script src="/lib/highlight/highlight.pack.js?v=20171001"></script><script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script><script type="text/javascript" src="/dist/jane.min.js?v=2.7.0"></script><script type="text/javascript">window.MathJax = {
      showProcessingMessages: false,
      messageStyle: 'none'
    };</script><script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script><script id="baidu_analytics">var _hmt = _hmt || [];
  (function() {
    if (window.location.hostname === 'localhost') return;
    var hm = document.createElement("script"); hm.async = true;
    hm.src = "https://hm.baidu.com/hm.js?a16b3275b071ec0efc507a05422a7156";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
  })();</script></body></html>